{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages and clone repo\n",
    "!pip install lightning\n",
    "!git clone https://github.com/mhbakalar/phla-prediction.git\n",
    "\n",
    "# Restart runtime after package installation\n",
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd phla-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "data_root = '/content/phla-prediction/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import lightning as L\n",
    "import torch\n",
    "\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "import models.datasets.phla_data\n",
    "import models.modules.transformer\n",
    "import models.modules.split_transformer\n",
    "\n",
    "class PeptidePrediction():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def run(self):\n",
    "        save_dir = data_root+\"logs\"\n",
    "\n",
    "        # Define parameters for sweep\n",
    "        parameter_dict = {'embedding_dim': [256],\n",
    "                          'heads': [16],\n",
    "                          'transformer_layers': [3]                          }\n",
    "\n",
    "        # Parameter sweep\n",
    "        for params in ParameterGrid(parameter_dict):\n",
    "            # Extract parameters\n",
    "            embedding_dim = params['embedding_dim']\n",
    "            heads = params['heads']\n",
    "            layers = params['transformer_layers']\n",
    "\n",
    "            # Configure data\n",
    "            hits_file = data_root+'data/hits_95.txt'\n",
    "            decoys_file = data_root+'data/decoys.txt'\n",
    "            aa_order_file = data_root+'data/amino_acid_ordering.txt'\n",
    "            allele_sequence_file = data_root+'data/alleles_95_variable.txt'\n",
    "\n",
    "            data = models.datasets.phla_data.PeptideHLADataModule(\n",
    "                hits_file=hits_file,\n",
    "                decoys_file=decoys_file,\n",
    "                aa_order_file=aa_order_file,\n",
    "                allele_sequence_file=allele_sequence_file,\n",
    "                decoy_mul=1,\n",
    "                decoy_pool_mul=10,\n",
    "                train_test_split=0.2,\n",
    "                batch_size=32,\n",
    "                predict_mode=False\n",
    "            )\n",
    "            data.prepare_data()\n",
    "\n",
    "            # Configure the model\n",
    "            model = models.modules.split_transformer.PeptideHLATransformer(\n",
    "                peptide_length=12,\n",
    "                allele_length=60,\n",
    "                dropout_rate=0.3,\n",
    "                embedding_dim=embedding_dim,\n",
    "                transformer_heads=heads,\n",
    "                transformer_layers=layers,\n",
    "                learning_rate=1e-4\n",
    "            )\n",
    "\n",
    "            # Create a logger\n",
    "            logger = TensorBoardLogger(\n",
    "                save_dir=save_dir,\n",
    "            )\n",
    "\n",
    "            checkpoint_callback = ModelCheckpoint(dirpath=logger.log_dir, save_top_k=2, monitor=\"val_loss\")\n",
    "            trainer = L.Trainer(\n",
    "                max_epochs=10,\n",
    "                logger=logger,\n",
    "                callbacks=[checkpoint_callback],\n",
    "                accelerator=\"gpu\",\n",
    "                reload_dataloaders_every_n_epochs=1\n",
    "            )\n",
    "            trainer.tune(model, datamodule=data)\n",
    "            trainer.fit(model, datamodule=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = PeptidePrediction()\n",
    "app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d6f6171c878022954ad2c480bec0b37cf777d596adaa7cc6e37da37919f1df6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
